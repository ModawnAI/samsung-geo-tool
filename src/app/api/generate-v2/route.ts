/**
 * GEO v2 Generation API Route
 * 7-Stage Pipeline with USP-Centric Architecture
 */

import { NextRequest, NextResponse } from 'next/server'
import { GoogleGenAI } from '@google/genai'
import { multiQuerySearch, getSectionContext } from '@/lib/rag/search'
import { isPineconeConfigured } from '@/lib/pinecone/client'
import {
  executeGEOv2Pipeline,
  extractUSPs,
  checkForFabrications,
  sanitizeContent,
  calculateGroundingQualityScore,
  getSourceTier,
  extractGroundingSources,
  aggregateGroundingMetadata,
  getAntiFabricationPrompt,
  PIPELINE_CONFIGS,
  type PipelineInput,
} from '@/lib/geo-v2'
import type {
  GEOv2GenerateResponse,
  PipelineProgress,
  GroundingSource,
  UniqueSellingPoint,
  FAQItem,
  CaseStudy,
  CaseStudyResult,
} from '@/types/geo-v2'
import type { ProductCategory, PlaybookSearchResult, PlaybookSection } from '@/types/playbook'

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY })

// ==========================================
// V2 REQUEST/RESPONSE TYPES
// ==========================================

interface GEOv2GenerateRequest {
  productName: string
  youtubeUrl: string
  srtContent: string
  existingDescription?: string
  keywords: string[]
  productCategory?: ProductCategory | 'all'
  usePlaybook?: boolean
  launchDate?: string
  pipelineConfig?: 'full' | 'quick' | 'grounded'
  language?: 'ko' | 'en'
}

interface GroundingSignal {
  term: string
  score: number
  source?: string
  recency?: string
}

// ==========================================
// V2 RESPONSE SCHEMAS
// ==========================================

const descriptionSchema = {
  type: 'object',
  properties: {
    preview: {
      type: 'string',
      description: 'First 130 characters preview for search results',
    },
    full: {
      type: 'string',
      description: 'Full SEO-optimized description (300-500 characters)',
    },
    vanityLinks: {
      type: 'array',
      items: { type: 'string' },
      description: 'Suggested vanity links for call-to-action',
    },
  },
  required: ['preview', 'full', 'vanityLinks'],
}

const faqSchema = {
  type: 'object',
  properties: {
    faqs: {
      type: 'array',
      items: {
        type: 'object',
        properties: {
          question: { type: 'string' },
          answer: { type: 'string' },
          linkedUSPs: {
            type: 'array',
            items: { type: 'string' },
          },
        },
        required: ['question', 'answer'],
      },
      description: '5-7 FAQs addressing real user queries, linked to USPs',
    },
    queryPatternOptimization: {
      type: 'boolean',
      description: 'Whether FAQs are optimized for query patterns',
    },
  },
  required: ['faqs', 'queryPatternOptimization'],
}

const caseStudySchema = {
  type: 'object',
  properties: {
    caseStudies: {
      type: 'array',
      items: {
        type: 'object',
        properties: {
          title: { type: 'string' },
          scenario: { type: 'string' },
          solution: { type: 'string' },
          linkedUSPs: {
            type: 'array',
            items: { type: 'string' },
          },
          evidence: {
            type: 'object',
            properties: {
              type: { type: 'string' },
              confidence: { type: 'string' },
            },
          },
        },
        required: ['title', 'scenario', 'solution'],
      },
    },
  },
  required: ['caseStudies'],
}

const chaptersSchema = {
  type: 'object',
  properties: {
    timestamps: {
      type: 'string',
      description: 'Video timestamps (format: "0:00 Section name")',
    },
    autoGenerated: {
      type: 'boolean',
      description: 'Whether chapters were auto-generated from SRT',
    },
  },
  required: ['timestamps', 'autoGenerated'],
}

const keywordsSchema = {
  type: 'object',
  properties: {
    product: {
      type: 'array',
      items: { type: 'string' },
      description: 'Product-specific keywords',
    },
    generic: {
      type: 'array',
      items: { type: 'string' },
      description: 'Generic category keywords',
    },
    densityScore: {
      type: 'number',
      description: 'Keyword density score 0-100',
    },
  },
  required: ['product', 'generic', 'densityScore'],
}

// ==========================================
// MAIN API HANDLER
// ==========================================

export async function POST(request: NextRequest) {
  const startTime = Date.now()

  try {
    const body: GEOv2GenerateRequest = await request.json()
    const {
      productName,
      youtubeUrl,
      srtContent,
      existingDescription,
      keywords,
      productCategory,
      usePlaybook = true,
      launchDate,
      pipelineConfig = 'full',
      language = 'ko',
    } = body

    // Validation
    if (!productName || !srtContent) {
      return NextResponse.json(
        { error: 'Product name and SRT content are required' },
        { status: 400 }
      )
    }

    console.log(`[GEO v2] Starting pipeline: ${pipelineConfig}`)
    console.log(`[GEO v2] Product: ${productName}, Keywords: ${keywords.length}`)

    // ==========================================
    // STAGE 0: PARALLEL DATA FETCHING
    // ==========================================
    const [groundingSignals, playbookContext] = await Promise.all([
      fetchGroundingSignals(productName, keywords, launchDate),
      (usePlaybook && isPineconeConfigured())
        ? fetchPlaybookContext(productName, keywords, productCategory)
        : Promise.resolve([]),
    ])

    console.log(`[GEO v2] Data fetched in ${Date.now() - startTime}ms`)
    console.log(`[GEO v2] Grounding signals: ${groundingSignals.length}, Playbook chunks: ${playbookContext.length}`)

    if (!process.env.GEMINI_API_KEY) {
      return NextResponse.json(getMockV2Response(productName, keywords))
    }

    // ==========================================
    // STAGE 1: DESCRIPTION GENERATION WITH GROUNDING
    // ==========================================
    const descriptionResult = await generateDescription(
      productName,
      srtContent,
      existingDescription,
      keywords,
      groundingSignals,
      playbookContext,
      language
    )

    // Extract grounding sources from description generation
    const descriptionGroundingSources = extractSourcesFromGrounding(descriptionResult.groundingChunks)

    console.log(`[GEO v2] Description generated with ${descriptionGroundingSources.length} sources`)

    // ==========================================
    // STAGE 1.5: USP EXTRACTION
    // ==========================================
    const uspResult = await extractUSPs({
      productName,
      srtContent,
      keywords,
      groundingSignals,
      groundingSources: descriptionGroundingSources,
    })

    console.log(`[GEO v2] USPs extracted: ${uspResult.usps.length}, Method: ${uspResult.extractionMethod}`)

    // ==========================================
    // STAGE 2 & 3: PARALLEL - CHAPTERS + FAQ
    // ==========================================
    const [chaptersResult, faqResult] = await Promise.all([
      generateChapters(srtContent, productName),
      generateFAQ(productName, srtContent, uspResult.usps, groundingSignals, language),
    ])

    console.log(`[GEO v2] Chapters: ${chaptersResult.timestamps.split('\n').length} entries`)
    console.log(`[GEO v2] FAQs: ${faqResult.faqs.length} Q&As`)

    // ==========================================
    // STAGE 4 & 5: PARALLEL - STEP-BY-STEP + CASE STUDIES
    // ==========================================
    const isTutorialContent = detectTutorialContent(srtContent)

    const [stepByStepResult, caseStudiesResult] = await Promise.all([
      isTutorialContent
        ? generateStepByStep(srtContent, productName, language)
        : Promise.resolve(null),
      generateCaseStudies(productName, uspResult.usps, groundingSignals, language),
    ])

    if (stepByStepResult) {
      console.log(`[GEO v2] Step-by-step: ${stepByStepResult.steps.length} steps`)
    }
    console.log(`[GEO v2] Case studies: ${caseStudiesResult.caseStudies.length} cases`)

    // ==========================================
    // STAGE 6: KEYWORDS EXTRACTION
    // ==========================================
    const keywordsResult = await generateKeywords(
      productName,
      srtContent,
      keywords,
      groundingSignals,
      language
    )

    // ==========================================
    // STAGE 6.5: HASHTAG GENERATION
    // ==========================================
    const hashtagResult = await generateHashtags(
      productName,
      descriptionResult.description.full,
      uspResult.usps,
      keywordsResult,
      language
    )

    console.log(`[GEO v2] Keywords: ${keywordsResult.product.length + keywordsResult.generic.length}`)
    console.log(`[GEO v2] Hashtags: ${hashtagResult.hashtags.length} (categorized)`)

    // ==========================================
    // STAGE 7: GROUNDING AGGREGATION
    // ==========================================
    const stageGroundingData = [
      {
        stage: 'description',
        sources: descriptionGroundingSources,
        searchQueries: groundingSignals.map(s => s.term),
      },
      {
        stage: 'usp_extraction',
        sources: extractUSPSources(uspResult.usps),
        searchQueries: [],
      },
      {
        stage: 'faq',
        sources: extractFAQSources(faqResult.faqs),
        searchQueries: [],
      },
      {
        stage: 'case_studies',
        sources: extractCaseStudySources(caseStudiesResult.caseStudies),
        searchQueries: [],
      },
    ]

    const groundingMetadata = aggregateGroundingMetadata(stageGroundingData)

    // ==========================================
    // FINAL SCORE CALCULATION
    // ==========================================
    const groundingQuality = calculateGroundingQualityScore({
      sources: groundingMetadata.sources,
      usps: uspResult.usps,
      totalSections: 7,
      sectionsWithGrounding: stageGroundingData.filter(s => s.sources.length > 0).length,
      contentLength: descriptionResult.description.full.length + faqResult.faqs.reduce((acc, f) => acc + f.answer.length, 0),
      citedContentLength: groundingMetadata.totalCitations * 200,
    })

    // Calculate component scores
    const keywordDensityScore = Math.min(15, Math.round(keywordsResult.densityScore / 100 * 15))
    const aiExposureScore = Math.min(25, Math.round((uspResult.groundingQuality / 100) * 25))
    const questionPatternsScore = Math.min(20, Math.round((faqResult.faqs.length / 7) * 20))
    const sentenceStructureScore = 12 // Would be calculated from actual content analysis
    const lengthComplianceScore = calculateLengthComplianceScore(descriptionResult.description.full)

    const finalScore = {
      keywordDensity: keywordDensityScore,
      aiExposure: aiExposureScore,
      questionPatterns: questionPatternsScore,
      sentenceStructure: sentenceStructureScore,
      lengthCompliance: lengthComplianceScore,
      groundingQuality,
      total: Math.round(
        (keywordDensityScore + aiExposureScore + questionPatternsScore +
          sentenceStructureScore + lengthComplianceScore + groundingQuality.total) * 100
      ) / 100,
    }

    console.log(`[GEO v2] Final score: ${finalScore.total}/100`)
    console.log(`[GEO v2] Pipeline completed in ${Date.now() - startTime}ms`)

    // ==========================================
    // BUILD RESPONSE
    // ==========================================
    const response: GEOv2GenerateResponse = {
      description: descriptionResult.description,
      uspResult,
      chapters: chaptersResult,
      faq: faqResult,
      stepByStep: stepByStepResult || undefined,
      caseStudies: caseStudiesResult,
      keywords: keywordsResult,
      hashtags: hashtagResult.hashtags,
      hashtagCategories: hashtagResult.categories,
      finalScore,
      groundingMetadata,
      progress: [],
    }

    return NextResponse.json(response)
  } catch (error) {
    console.error('[GEO v2] Pipeline error:', error)
    return NextResponse.json(
      { error: 'Failed to generate v2 content', details: error instanceof Error ? error.message : String(error) },
      { status: 500 }
    )
  }
}

// ==========================================
// STAGE IMPLEMENTATIONS
// ==========================================

/**
 * Stage 1: Generate Description with Google Grounding
 * Based on AEO_GEO_PROMPTS_DOCUMENTATION.md - createDescriptionPrompt()
 */
async function generateDescription(
  productName: string,
  srtContent: string,
  existingDescription: string | undefined,
  keywords: string[],
  groundingSignals: GroundingSignal[],
  playbookContext: PlaybookSearchResult[],
  language: 'ko' | 'en'
): Promise<{
  description: { preview: string; full: string; vanityLinks: string[] }
  groundingChunks: Array<{ web?: { uri: string; title: string } }>
}> {
  const antiFabPrompt = getAntiFabricationPrompt('high')

  const systemInstruction = `You are a GEO/AEO optimization expert for Samsung content.
${antiFabPrompt}

CONTEXT:
- Product: ${productName}
- Video Title: ${productName} Overview
- Video Transcript: ${srtContent.substring(0, 3000)}...
${existingDescription ? `- Existing Description (reference): ${existingDescription}` : ''}

GROUNDING INSTRUCTION - MANDATORY QUERY EXECUTION PROTOCOL:

üî¥ CRITICAL: You MUST EXECUTE ALL queries listed below. This is MANDATORY, not optional.

üìã VIDEO-BASED SEARCH STRATEGY:
Generate 10-15 search queries based ONLY on features mentioned in the video content.

QUERY GENERATION PROCESS:
1. **Extract Features from Video**: Identify ALL features explicitly mentioned
2. **Generate Numbered Query List**: Create [REQUIRED] queries for each feature
3. **Site Diversification Strategy** (MANDATORY - use all 5 site types):
   - Official: "${productName} [feature] specifications site:samsung.com" [REQUIRED]
   - Community: "${productName} [feature] reddit OR site:reddit.com/r/samsung" [REQUIRED]
   - Review Sites: "${productName} [feature] site:gsmarena.com OR site:techradar.com" [REQUIRED]
   - Video Content: "${productName} [feature] site:youtube.com" [REQUIRED]
   - General: "${productName} [feature] vs [competitor]" [REQUIRED]

üìä MANDATORY QUERY DISTRIBUTION:
- 3-4 queries with site:samsung.com [REQUIRED]
- 2-3 queries with reddit OR site:reddit.com [REQUIRED]
- 2-3 queries with site:gsmarena.com OR site:techradar.com [REQUIRED]
- 2-3 queries with site:youtube.com [REQUIRED]
- 2-3 queries without site restrictions (general search) [REQUIRED]

TASK:
Generate a YouTube description optimized for GEO and AEO.

RULES (CRITICAL):
1. First 130 characters MUST contain:
   - Product name
   - Key feature
   - User benefit
   Example: "Introducing the all-new Galaxy Z Flip7. From pro-level 50 MP selfies..."

2. Structure:
   - Opening (130 chars)
   - Learn more CTA: "Learn more: http://smsng.co/[VanityLink]"
   - Content body (natural, not keyword-stuffed)
   - Include 1-2 expert attribution quotes for credibility

3. GEO/AEO Principles:
   - Use chunking (modular sections)
   - Avoid vague terms ("innovative", "eco-friendly" without context)
   - Add measurable context
   - Use semantic HTML structure mentally (H1, H2 hierarchy)

4. Expert Attribution (GEO/AEO 2025 Best Practice):
   - Include 1-2 authoritative quotes from Samsung experts or industry analysts
   - Format: "According to Samsung Mobile's product team, ${productName}..."
   - Build trust with AI systems through verifiable sources

CRITICAL: SCORING OPTIMIZATION (TARGET: 85+ points)

1. KEYWORD DENSITY (17-19 points target):
   ‚úÖ Place ${productName} within first 50 characters of first_130
   ‚úÖ Include 3+ feature keywords: camera, ai, display, battery, performance
   ‚úÖ Use 2+ synonym groups naturally:
      - phone/device/smartphone/mobile
      - camera/lens/photography/photo
      - display/screen/panel
   ‚úÖ Keep product name repetition under 10% of total words

2. AI EXPOSURE (25-28 points target):
   ‚úÖ Include 3+ competitive keywords: camera, megapixel, foldable, ai, smartphone
   ‚úÖ Use specific technical specifications ("50 MP", "5000mAh", "6.7 inch OLED")
   ‚úÖ Mention brand/tech terms: Samsung, Galaxy, AI, OLED, 5G, Knox, Snapdragon

3. SENTENCE STRUCTURE (13-14 points target):
   ‚úÖ Include 2+ measurable specifications with numbers/units
   ‚úÖ Use natural, specific language (avoid "innovative", "revolutionary")
   ‚úÖ Maintain entity density above 1%

4. LENGTH COMPLIANCE (13-14 points target):
   ‚úÖ first_130: Must be 110-130 characters
   ‚úÖ full_description: 300-1000 characters optimal

## BRAND GUIDELINES
${playbookContext.map(ctx => ctx.content).join('\n\n').slice(0, 2000)}

Output in ${language === 'ko' ? 'Korean' : 'English'}.`

  const userPrompt = `Generate optimized description for ${productName}:

## VIDEO TRANSCRIPT
${srtContent.slice(0, 3000)}

## EXISTING DESCRIPTION (if any)
${existingDescription || 'None provided'}

## TARGET KEYWORDS
${keywords.join(', ')}

## USER INTENT SIGNALS
${groundingSignals.slice(0, 5).map(s => `- ${s.term} (${s.score}%)`).join('\n')}

OUTPUT FORMAT (JSON):
{
  "preview": "exact first 130 characters (110-130 chars, must contain product name + key feature + benefit)",
  "full": "complete description without timestamps/FAQ/hashtags (300-1000 chars)",
  "vanityLinks": ["suggested vanity link name (e.g., ZFlip7_Intro_yt)"]
}`

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: userPrompt,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: descriptionSchema,
        temperature: 0.7,
        maxOutputTokens: 1500,
        // Enable Google Search grounding
        tools: [{ googleSearch: {} }],
      },
    })

    const content = response.text
    if (!content) throw new Error('No description generated')

    const parsed = JSON.parse(content)

    // Sanitize for fabrications
    const sanitized = sanitizeContent(parsed.full)
    if (sanitized.wasModified) {
      console.log(`[Description] Sanitized ${sanitized.modifications.length} potential fabrications`)
    }

    // Extract grounding chunks from response
    const groundingChunks = (response as unknown as {
      candidates?: Array<{
        groundingMetadata?: {
          groundingChunks?: Array<{ web?: { uri: string; title: string } }>
        }
      }>
    }).candidates?.[0]?.groundingMetadata?.groundingChunks || []

    return {
      description: {
        preview: parsed.preview || sanitized.sanitized.slice(0, 130),
        full: sanitized.sanitized,
        vanityLinks: parsed.vanityLinks || [],
      },
      groundingChunks,
    }
  } catch (error) {
    console.error('[Description] Generation failed:', error)
    return {
      description: {
        preview: `${productName}Ïùò Î™®Îì† Í≤ÉÏùÑ ÏïåÏïÑÎ≥¥ÏÑ∏Ïöî.`,
        full: `${productName}Ïùò Ï£ºÏöî Í∏∞Îä•Í≥º ÌäπÏßïÏùÑ ÏÜåÍ∞úÌï©ÎãàÎã§. ${keywords.slice(0, 3).join(', ')} Îì± Îã§ÏñëÌïú Í∏∞Îä•ÏùÑ ÌôïÏù∏Ìï¥Î≥¥ÏÑ∏Ïöî.`,
        vanityLinks: [`samsung.com/${productName.toLowerCase().replace(/\s+/g, '-')}`],
      },
      groundingChunks: [],
    }
  }
}

/**
 * Stage 2: Generate Chapters
 * Based on AEO_GEO_PROMPTS_DOCUMENTATION.md - createChaptersPrompt()
 */
async function generateChapters(
  srtContent: string,
  productName: string
): Promise<{ timestamps: string; autoGenerated: boolean }> {
  const systemInstruction = `You are creating GEO/AEO-optimized timestamp chapters for YouTube video navigation.

CRITICAL: Chapters are a strategic SEO asset that:
1. Improve video discoverability in search results
2. Help AI systems understand video structure
3. Enable direct navigation to relevant content
4. Appear in YouTube search and Google video results

CHAPTER QUALITY CRITERIA (GEO/AEO Optimization):

‚úÖ INCLUDE chapters that:
- Describe product features or specifications (e.g., "50MP Camera", "Design", "Display")
- Highlight key functionalities (e.g., "Now Brief", "Gemini Live", "FlexWindow")
- Explain use cases or demos (e.g., "Photo Demo", "Unboxing", "Setup Guide")
- Represent major video sections (e.g., "Intro", "Conclusion", "Key Features")
- Use searchable keywords related to the product
- Are meaningful standalone (users can understand without watching full video)

‚ùå EXCLUDE chapters that:
- Contain personal names or casual references (e.g., "mochi's dog show")
- Are vague or generic without context (e.g., "Part 1", "Next", "More")
- Reference non-product content (e.g., "Background music", "Credits")
- Don't relate to product features or value proposition

CHAPTER TITLE RULES:

1. LENGTH: 2-5 words maximum (concise and scannable)

2. KEYWORD OPTIMIZATION:
   - Include product feature names when relevant
   - Use terminology users would search for
   - Avoid marketing fluff ("Amazing", "Incredible")
   - Use specific technical terms ("50MP", "OLED", "AI")

3. CLARITY:
   - Descriptive and self-explanatory
   - Title alone should convey section purpose
   - Capitalize first letter of each major word

4. SEARCHABILITY:
   - Would this appear in search results?
   - Does it answer "what's in this section?"
   - Is it product-feature relevant?

EXAMPLES (Good vs Bad):

‚úÖ GOOD CHAPTERS:
- "00:00 Intro"
- "00:16 Design"
- "00:33 50MP Camera"
- "01:00 Now Brief"
- "01:37 Gemini Live"
- "02:15 Battery Life"

‚ùå BAD CHAPTERS:
- "00:45 mochi's dog show" ‚Üí Personal reference
- "01:20 Random thoughts" ‚Üí Vague
- "02:30 Really cool stuff" ‚Üí Marketing fluff`

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: `Generate GEO/AEO-optimized timestamp chapters for ${productName}:

## SRT TRANSCRIPT
${srtContent.slice(0, 4000)}

## TASK
Create 5-10 meaningful chapter markers based on content transitions.
Each chapter should be SEO-optimized and searchable.

OUTPUT FORMAT (JSON):
{
  "timestamps": "00:00 Intro\\n00:16 Design\\n00:33 50MP Camera\\n...",
  "autoGenerated": true
}`,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: chaptersSchema,
        temperature: 0.5,
        maxOutputTokens: 800,
      },
    })

    const content = response.text
    if (!content) throw new Error('No chapters generated')

    const parsed = JSON.parse(content)
    return {
      timestamps: parsed.timestamps || '',
      autoGenerated: true,
    }
  } catch (error) {
    console.error('[Chapters] Generation failed:', error)
    return {
      timestamps: `0:00 ${productName} ÏÜåÍ∞ú\n0:30 Ï£ºÏöî Í∏∞Îä•\n1:00 ÏÉÅÏÑ∏ Î¶¨Î∑∞\n2:00 Ï¥ùÌèâ`,
      autoGenerated: true,
    }
  }
}

/**
 * Stage 3: Generate FAQ with Query Fan-Out Methodology
 * Based on AEO_GEO_PROMPTS_DOCUMENTATION.md - createFAQPrompt()
 */
async function generateFAQ(
  productName: string,
  srtContent: string,
  usps: UniqueSellingPoint[],
  groundingSignals: GroundingSignal[],
  language: 'ko' | 'en'
): Promise<{ faqs: FAQItem[]; queryPatternOptimization: boolean }> {
  const antiFabPrompt = getAntiFabricationPrompt('medium')

  const uspSummary = usps.map((usp, i) =>
    `USP ${i + 1}: ${usp.feature} - ${usp.userBenefit}`
  ).join('\n')

  const systemInstruction = `You are creating FAQ for Samsung product content optimized for Query Fan-Out.

## QUERY FAN-OUT STRATEGY
AI systems generate multiple related subqueries from a single user question. Address these patterns:
1. Core feature question: How USPs solve user problems
2. Benefit/Use case question: Real-world applications of USPs
3. Implementation/How-to question: How to use USP features
4. Specification question: Technical details of USPs
5. Troubleshooting question: Common issues with USP features
6. Alternative question: When USPs provide advantage
7. Comparative question: How USPs differentiate from alternatives

## QUESTION RULES (CRITICAL)
1. Questions MUST:
   - Be 10-15 words (conversational search pattern, NOT 2-3 words)
   - Start with How/What/Why/When/Where
   - Reflect real user intent with natural language
   - Cover different query fan-out angles
   - Be specific to product features or usage scenarios

2. QUESTION EXAMPLES (Good vs Bad):
   ‚ùå Bad: "What is ${productName}'s battery life?" (too short, 7 words)
   ‚úÖ Good: "How long does the ${productName} battery last with heavy social media use and video streaming throughout the day?" (18 words, conversational)

   ‚ùå Bad: "What are the camera features?" (vague, 5 words)
   ‚úÖ Good: "What makes the ${productName} camera better for selfies compared to traditional smartphones like iPhone 16?" (16 words, comparative)

## ANSWER RULES
1. Answers MUST:
   - Be direct and factual (passage-level complete)
   - Include measurable details (specs, numbers, percentages)
   - Avoid vague marketing language ("innovative", "eco-friendly")
   - Be semantically complete (answer works independently)
   - Be concise (2-4 sentences, 50-100 words)

## GROUNDING INSTRUCTION - MANDATORY FAQ QUERY EXECUTION PROTOCOL

üî¥ CRITICAL: You MUST EXECUTE queries for grounding before generating FAQs.

QUERY GENERATION per USP/Feature from Video (use all 5 site types):

1. **Official Specifications** [REQUIRED]:
   - "${productName} [USP feature] specifications site:samsung.com"

2. **Community Discussions** [REQUIRED]:
   - "${productName} [USP feature] reddit OR site:reddit.com/r/samsung"

3. **Expert Reviews** [REQUIRED]:
   - "${productName} [USP feature] site:gsmarena.com OR site:techradar.com"

4. **Video Demonstrations** [REQUIRED]:
   - "${productName} [USP feature] site:youtube.com"

5. **Competitive Comparisons** [REQUIRED]:
   - "${productName} [USP feature] vs [competitor]"

## SCORING OPTIMIZATION (TARGET: 85+ points)

QUESTION PATTERNS (17-20 points target):
‚úÖ ALL questions MUST start with How/What/Why/When/Where (5pts)
‚úÖ Questions must be 10-20 words, conversational and natural (5pts)
‚úÖ Answers must be 50-150 words, direct and factual (5pts)
‚úÖ Generate exactly 5-7 FAQs covering different query fan-out angles (5pts)

${antiFabPrompt}

Output in ${language === 'ko' ? 'Korean' : 'English'}.`

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: `Generate FAQ for ${productName}:

## UNIQUE SELLING POINTS (from grounded research)
${uspSummary}

## USER SEARCH SIGNALS
${groundingSignals.slice(0, 5).map(s => `- ${s.term}`).join('\n')}

## VIDEO TRANSCRIPT
${srtContent.slice(0, 3000)}

## TASK
Generate 5-7 Q&A pairs optimized for AEO (Answer Engine Optimization) using Query Fan-Out methodology.
Each question must be 10-15 words, conversational, and cover different query fan-out angles.`,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: faqSchema,
        temperature: 0.7,
        maxOutputTokens: 2000,
        tools: [{ googleSearch: {} }],
      },
    })

    const content = response.text
    if (!content) throw new Error('No FAQ generated')

    const parsed = JSON.parse(content)
    return {
      faqs: parsed.faqs || [],
      queryPatternOptimization: true,
    }
  } catch (error) {
    console.error('[FAQ] Generation failed:', error)
    return {
      faqs: [
        {
          question: `${productName}Ïùò Í∞ÄÏû• ÌÅ∞ ÌäπÏßïÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?`,
          answer: usps[0]?.differentiation || 'ÏµúÏã† Í∏∞Ïà†ÏùÑ ÌÉëÏû¨Ìïú ÌîÑÎ¶¨ÎØ∏ÏóÑ Ï†úÌíàÏûÖÎãàÎã§.',
          linkedUSPs: usps[0] ? [usps[0].feature] : [],
          confidence: 'medium',
        },
      ],
      queryPatternOptimization: false,
    }
  }
}

/**
 * Stage 4: Generate Step-by-Step (for tutorial content)
 * Based on AEO_GEO_PROMPTS_DOCUMENTATION.md - createStepByStepPrompt()
 */
async function generateStepByStep(
  srtContent: string,
  productName: string,
  language: 'ko' | 'en'
): Promise<{ steps: string[]; isTutorialContent: boolean; reasoning?: string }> {
  const systemInstruction = `You are determining if step-by-step instructions are needed for this video.

## TASK
1. Determine if step-by-step instructions would benefit users
2. If yes, create them in a clear, actionable format

## CRITERIA FOR "YES" (needed = true):
‚úÖ Video is How-to, Tutorial, or Guided Demo
‚úÖ Feature requires specific sequence of actions
‚úÖ User might struggle without guidance
‚úÖ Video demonstrates a process or workflow

## CRITERIA FOR "NO" (needed = false):
‚ùå Purely promotional (Intro films, product showcases)
‚ùå No actionable steps shown
‚ùå Too simple to require instructions
‚ùå Conceptual or informational only

## STEP FORMAT RULES (if needed = true):
1. Each step must be clear and actionable
2. Use imperative verbs: "Open", "Navigate", "Select", "Enable"
3. Include specific UI elements or settings names
4. Number steps sequentially
5. Keep each step concise (1-2 sentences)
6. Include expected outcomes where relevant

## EXAMPLES:
‚úÖ Good Step: "Step 1: Open Settings app and navigate to 'Display' section."
‚ùå Bad Step: "First you should maybe look at the settings."

‚úÖ Good Step: "Step 2: Toggle 'Always On Display' to enable the feature."
‚ùå Bad Step: "Turn on the display thing."

Output in ${language === 'ko' ? 'Korean' : 'English'}.`

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: `Analyze this video content for ${productName} and determine if step-by-step instructions are needed:

## VIDEO TRANSCRIPT
${srtContent.slice(0, 3000)}

## TASK
1. First determine if this content needs step-by-step instructions (YES/NO criteria above)
2. If yes, create clear, actionable steps
3. Provide reasoning for your decision`,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: {
          type: 'object',
          properties: {
            needed: {
              type: 'boolean',
              description: 'Whether step-by-step instructions are needed',
            },
            reasoning: {
              type: 'string',
              description: '2-3 sentences explaining why step-by-step is or isn\'t needed',
            },
            steps: {
              type: 'array',
              items: { type: 'string' },
              description: 'Clear, actionable steps if needed',
            },
          },
          required: ['needed', 'reasoning', 'steps'],
        },
        temperature: 0.5,
        maxOutputTokens: 1200,
      },
    })

    const content = response.text
    if (!content) throw new Error('No steps generated')

    const parsed = JSON.parse(content)
    return {
      steps: parsed.needed ? (parsed.steps || []) : [],
      isTutorialContent: parsed.needed || false,
      reasoning: parsed.reasoning,
    }
  } catch (error) {
    console.error('[Step-by-step] Generation failed:', error)
    return { steps: [], isTutorialContent: false }
  }
}

/**
 * Stage 5: Generate Case Studies
 * Enhanced with anti-fabrication and realistic use case guidelines
 */
async function generateCaseStudies(
  productName: string,
  usps: UniqueSellingPoint[],
  groundingSignals: GroundingSignal[],
  language: 'ko' | 'en'
): Promise<CaseStudyResult> {
  const antiFabPrompt = getAntiFabricationPrompt('high')

  const uspContext = usps.slice(0, 3).map((usp, i) =>
    `USP ${i + 1}: ${usp.feature}\n  - Benefit: ${usp.userBenefit}\n  - Confidence: ${usp.confidence}`
  ).join('\n\n')

  const systemInstruction = `You are creating realistic use case scenarios for Samsung products.

## CASE STUDY QUALITY STANDARDS

### REALISTIC SCENARIOS:
1. Use relatable user personas (e.g., "content creator", "business professional", "parent")
2. Describe specific situations where USP features solve real problems
3. Include context that matches the target audience's lifestyle

### ANTI-FABRICATION RULES:
${antiFabPrompt}

### HEDGING LANGUAGE FOR UNVERIFIED CLAIMS:
When outcomes cannot be verified, use safe language:
- "Designed to help users..."
- "Enables [persona] to..."
- "Potential improvement in..."
- "Built to support..."

### DO NOT:
‚ùå Invent specific percentages or statistics
‚ùå Claim "studies show" without sources
‚ùå Make competitive claims without evidence
‚ùå Use superlatives like "best", "revolutionary", "unprecedented"

### DO:
‚úÖ Use specific feature names and specifications
‚úÖ Connect features to user benefits
‚úÖ Include realistic usage contexts
‚úÖ Cite USP evidence where available

Output in ${language === 'ko' ? 'Korean' : 'English'}.`

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: `Generate realistic case studies for ${productName}:

## USPs TO DEMONSTRATE
${uspContext}

## USER INTEREST SIGNALS
${groundingSignals.slice(0, 3).map(s => `- ${s.term}`).join('\n')}

## TASK
Create 2-3 realistic use case scenarios that:
1. Demonstrate specific USP benefits
2. Are relatable to target users
3. Include realistic outcomes based on actual features
4. Use hedging language for claims without verification`,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: caseStudySchema,
        temperature: 0.7,
        maxOutputTokens: 1500,
        tools: [{ googleSearch: {} }],
      },
    })

    const content = response.text
    if (!content) throw new Error('No case studies generated')

    const parsed = JSON.parse(content)
    return {
      caseStudies: parsed.caseStudies || [],
      extractionMethod: 'grounded',
    }
  } catch (error) {
    console.error('[Case Studies] Generation failed:', error)
    return { caseStudies: [], extractionMethod: 'generative' }
  }
}

/**
 * Stage 6: Generate Keywords with GEO/AEO Scoring
 * Based on AEO_GEO_PROMPTS_DOCUMENTATION.md - createKeywordsPrompt()
 */
async function generateKeywords(
  productName: string,
  srtContent: string,
  inputKeywords: string[],
  groundingSignals: GroundingSignal[],
  language: 'ko' | 'en'
): Promise<{
  product: string[];
  generic: string[];
  densityScore: number;
  questionScore?: number;
  structureScore?: number;
  lengthScore?: number;
  preliminaryTotal?: number;
}> {
  const systemInstruction = `You are extracting and analyzing keywords for GEO/AEO scoring.

## CATEGORIES

### Product-specific Keywords:
- Product names and model numbers (e.g., Galaxy Z Flip7, Galaxy S25 Ultra)
- Unique features and proprietary terms (e.g., FlexWindow, ProVisual Engine, Galaxy AI)
- Brand identifiers (Samsung, Galaxy, One UI)
- Specific specifications (e.g., 50 MP camera, 3.4-inch display)

### Generic Competitive Keywords:
- Industry terms (foldable phone, smartphone, AI camera)
- Use case terms (selfie, mobile photography, productivity)
- Benefit terms (hands-free, portable, compact)
- Category descriptors (premium, flagship, compact)

## SCORING CRITERIA (70 points total - AI exposure calculated separately)

### 1. KEYWORD DENSITY (20pts):
- Product name in first 30 characters: 5pts
- 3+ feature keywords present: 5pts
- Natural placement (no stuffing): 5pts
- Synonym usage (variety): 5pts

### 2. QUESTION PATTERNS (20pts):
- How/What/Why/When/Where questions: 5pts
- User intent reflected: 5pts
- Direct, clear answers: 5pts
- 4-7 FAQ count: 5pts

### 3. SENTENCE STRUCTURE (15pts):
- Chunkable content (modular sections): 5pts
- Lists/tables/structured format: 5pts
- Semantic clarity (no vague terms): 5pts

### 4. LENGTH COMPLIANCE (15pts):
- First 130 chars optimized: 5pts
- Description under 5000 chars: 5pts
- Appropriate detail level: 5pts

## OUTPUT REQUIREMENTS
Extract keywords that maximize discoverability while maintaining natural language flow.
Prioritize keywords that match user search intent and trending signals.

Output in ${language === 'ko' ? 'Korean' : 'English'}.`

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: `Extract and analyze keywords for ${productName}:

## VIDEO TRANSCRIPT
${srtContent.slice(0, 2000)}

## USER INPUT KEYWORDS
${inputKeywords.join(', ')}

## TRENDING SIGNALS
${groundingSignals.slice(0, 5).map(s => s.term).join(', ')}

## TASK
1. Extract and categorize keywords (product-specific and generic)
2. Score based on GEO/AEO criteria
3. Ensure natural keyword placement recommendations`,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: {
          type: 'object',
          properties: {
            product: {
              type: 'array',
              items: { type: 'string' },
              description: 'Product-specific keywords',
            },
            generic: {
              type: 'array',
              items: { type: 'string' },
              description: 'Generic competitive keywords',
            },
            densityScore: {
              type: 'number',
              description: 'Keyword density score (0-20)',
            },
            questionScore: {
              type: 'number',
              description: 'Question patterns score (0-20)',
            },
            structureScore: {
              type: 'number',
              description: 'Sentence structure score (0-15)',
            },
            lengthScore: {
              type: 'number',
              description: 'Length compliance score (0-15)',
            },
            preliminaryTotal: {
              type: 'number',
              description: 'Total preliminary score (0-70)',
            },
          },
          required: ['product', 'generic', 'densityScore'],
        },
        temperature: 0.5,
        maxOutputTokens: 1000,
      },
    })

    const content = response.text
    if (!content) throw new Error('No keywords generated')

    const parsed = JSON.parse(content)
    return {
      product: parsed.product || [],
      generic: parsed.generic || [],
      densityScore: parsed.densityScore || 50,
      questionScore: parsed.questionScore,
      structureScore: parsed.structureScore,
      lengthScore: parsed.lengthScore,
      preliminaryTotal: parsed.preliminaryTotal,
    }
  } catch (error) {
    console.error('[Keywords] Generation failed:', error)
    return {
      product: [productName, 'Samsung', 'Galaxy'],
      generic: inputKeywords,
      densityScore: 50,
    }
  }
}

// ==========================================
// HELPER FUNCTIONS
// ==========================================

/**
 * Fetch grounding signals from Perplexity
 */
async function fetchGroundingSignals(
  productName: string,
  keywords: string[],
  launchDate?: string
): Promise<GroundingSignal[]> {
  try {
    const apiKey = process.env.PERPLEXITY_API_KEY
    if (!apiKey) {
      console.warn('[Grounding] No Perplexity API key')
      return generateFallbackSignals(productName, keywords)
    }

    const queries = [
      `${productName} reviews 2024 2025`,
      `${productName} features specifications`,
      `${productName} ${keywords[0] || 'camera'} performance`,
    ]

    const results = await Promise.all(
      queries.map(query =>
        fetch('https://api.perplexity.ai/search', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            query,
            max_results: 5,
            max_tokens_per_page: 512,
          }),
        })
          .then(r => r.ok ? r.json() : { results: [] })
          .then(d => d.results || [])
          .catch(() => [])
      )
    )

    const allResults = results.flat()
    return extractSignalsFromResults(allResults, keywords)
  } catch (error) {
    console.error('[Grounding] Failed:', error)
    return generateFallbackSignals(productName, keywords)
  }
}

/**
 * Extract signals from search results
 */
function extractSignalsFromResults(
  results: Array<{ title?: string; snippet?: string; url?: string; date?: string }>,
  userKeywords: string[]
): GroundingSignal[] {
  const signalMap = new Map<string, { count: number; sources: string[]; recency?: string }>()

  const intentPatterns = [
    'camera', 'battery', 'display', 'performance', 'AI', 'Galaxy AI',
    'design', 'charging', 'storage', 'price', 'comparison', 'review',
    'Ïπ¥Î©îÎùº', 'Î∞∞ÌÑ∞Î¶¨', 'ÎîîÏä§ÌîåÎ†àÏù¥', 'ÏÑ±Îä•', 'Í∞ÄÍ≤©', 'ÎîîÏûêÏù∏',
  ]

  for (const result of results) {
    const text = `${result.title || ''} ${result.snippet || ''}`.toLowerCase()

    for (const pattern of intentPatterns) {
      if (text.includes(pattern.toLowerCase())) {
        const existing = signalMap.get(pattern) || { count: 0, sources: [] }
        existing.count++
        if (result.url) existing.sources.push(result.url)
        if (result.date && !existing.recency) existing.recency = result.date
        signalMap.set(pattern, existing)
      }
    }

    for (const keyword of userKeywords) {
      if (text.includes(keyword.toLowerCase())) {
        const existing = signalMap.get(keyword) || { count: 0, sources: [] }
        existing.count += 2
        signalMap.set(keyword, existing)
      }
    }
  }

  const maxCount = Math.max(...Array.from(signalMap.values()).map(v => v.count), 1)

  return Array.from(signalMap.entries())
    .map(([term, data]) => ({
      term,
      score: Math.round((data.count / maxCount) * 100),
      source: data.sources[0],
      recency: data.recency,
    }))
    .sort((a, b) => b.score - a.score)
    .slice(0, 15)
}

/**
 * Generate fallback signals when API unavailable
 */
function generateFallbackSignals(productName: string, keywords: string[]): GroundingSignal[] {
  const defaultSignals = ['camera', 'battery', 'display', 'performance', 'AI', 'design']
  return [...keywords, ...defaultSignals].slice(0, 10).map((term, i) => ({
    term,
    score: 100 - i * 10,
  }))
}

/**
 * Fetch playbook context
 */
async function fetchPlaybookContext(
  productName: string,
  keywords: string[],
  productCategory?: ProductCategory | 'all'
): Promise<PlaybookSearchResult[]> {
  try {
    const queries = [
      `Samsung brand guidelines ${productName}`,
      `GEO optimization AI search content`,
      `Samsung tone of voice writing style`,
      ...keywords.slice(0, 2).map(k => `Samsung ${k} marketing`),
    ]

    const ragContext = await multiQuerySearch(queries, {
      productCategory,
      topKPerQuery: 3,
      finalTopN: 8,
      deduplicateByContent: true,
    })

    return ragContext.results
  } catch (error) {
    console.error('[Playbook] Failed:', error)
    return []
  }
}

/**
 * Extract sources from grounding chunks
 */
function extractSourcesFromGrounding(
  chunks: Array<{ web?: { uri: string; title: string } }>
): GroundingSource[] {
  return extractGroundingSources(chunks)
}

/**
 * Extract sources from USPs
 */
function extractUSPSources(usps: UniqueSellingPoint[]): GroundingSource[] {
  const sources: GroundingSource[] = []
  for (const usp of usps) {
    if (usp.evidence.sources) {
      for (const source of usp.evidence.sources) {
        if (source.startsWith('http')) {
          sources.push({
            uri: source,
            title: 'USP Evidence',
            usedIn: ['usp_extraction'],
            tier: getSourceTier(source),
          })
        }
      }
    }
  }
  return sources
}

/**
 * Extract sources from FAQs
 */
function extractFAQSources(faqs: FAQItem[]): GroundingSource[] {
  // FAQs may reference sources in answers - extract URLs
  const sources: GroundingSource[] = []
  const urlRegex = /https?:\/\/[^\s]+/g

  for (const faq of faqs) {
    const matches = faq.answer.match(urlRegex) || []
    for (const url of matches) {
      sources.push({
        uri: url,
        title: 'FAQ Reference',
        usedIn: ['faq'],
        tier: getSourceTier(url),
      })
    }
  }
  return sources
}

/**
 * Extract sources from case studies
 */
function extractCaseStudySources(caseStudies: CaseStudy[]): GroundingSource[] {
  const sources: GroundingSource[] = []
  const urlRegex = /https?:\/\/[^\s]+/g

  for (const study of caseStudies) {
    const text = `${study.scenario} ${study.solution}`
    const matches = text.match(urlRegex) || []
    for (const url of matches) {
      sources.push({
        uri: url,
        title: 'Case Study Reference',
        usedIn: ['case_studies'],
        tier: getSourceTier(url),
      })
    }
  }
  return sources
}

/**
 * Detect if content is tutorial/how-to
 */
function detectTutorialContent(srtContent: string): boolean {
  const tutorialIndicators = [
    'Î∞©Î≤ï', 'how to', 'Îã®Í≥Ñ', 'step', 'Îî∞Îùº', 'follow',
    'ÏÑ§Ï†ï', 'setup', 'ÏÇ¨Ïö©Î≤ï', 'guide', 'ÌäúÌÜ†Î¶¨Ïñº', 'tutorial',
  ]

  const lowerContent = srtContent.toLowerCase()
  return tutorialIndicators.some(indicator =>
    lowerContent.includes(indicator.toLowerCase())
  )
}

/**
 * Calculate length compliance score
 */
function calculateLengthComplianceScore(description: string): number {
  const length = description.length
  if (length >= 300 && length <= 500) return 15
  if (length >= 250 && length <= 550) return 12
  if (length >= 200 && length <= 600) return 9
  if (length >= 150 && length <= 700) return 6
  return 3
}

/**
 * Generate strategic hashtags for YouTube SEO optimization
 * Uses AI to create categorized hashtags optimized for discovery
 */
async function generateHashtags(
  productName: string,
  description: string,
  usps: UniqueSellingPoint[],
  keywords: { product: string[]; generic: string[] },
  language: 'ko' | 'en'
): Promise<{
  hashtags: string[]
  categories: {
    brand: string[]
    features: string[]
    industry: string[]
  }
  reasoning?: string
}> {
  const systemInstruction = `You are generating strategic hashtags for YouTube SEO optimization.

## YOUR MISSION
Create 5-8 strategic hashtags optimized for YouTube discovery and SEO.

## HASHTAG STRATEGY

### 1. BRAND HASHTAGS (1-2 required)
- Product name without spaces: #GalaxyZFlip7
- Brand tags: #Samsung #GalaxyAI #WithGalaxy

### 2. FEATURE HASHTAGS (2-3 required)
- From USP features and categories
- Technical specifications (e.g., #50MPCamera #FlexWindow #FoldablePhone)
- Key capabilities (e.g., #AICamera #ProVisualEngine)

### 3. INDUSTRY HASHTAGS (2-3 required)
- Broader category terms for discovery
- Trending tech hashtags
- Use case hashtags (e.g., #MobilePhotography #TechReview #Smartphone)

## FORMATTING RULES
1. No spaces - use CamelCase for readability
2. Start with # symbol
3. Keep each hashtag under 20 characters
4. Total character count under 100
5. First 3 hashtags appear in YouTube search - prioritize discoverability

## PRIORITIZATION ORDER
- Position 1: Product name (most specific)
- Position 2-3: Key differentiating features
- Position 4-5: Category/industry terms
- Position 6-8: Trending/broad reach terms

## FORBIDDEN
‚ùå Generic tags like #tech #phone #new
‚ùå Overly long hashtags (>20 characters)
‚ùå Competitor brand names (iPhone, Pixel, etc.)
‚ùå Irrelevant trending tags

## LANGUAGE CONSIDERATION
${language === 'ko' ? '- Include 1-2 Korean hashtags for local discovery (e.g., #ÏÇºÏÑ±, #Í∞§Îü≠Ïãú)' : '- Use English-only hashtags for global reach'}

Output must be valid JSON.`

  const userPrompt = `Generate strategic hashtags for this Samsung product:

## PRODUCT
${productName}

## DESCRIPTION EXCERPT
${description.substring(0, 500)}...

## KEY FEATURES (USPs)
${usps.map(u => `- ${u.feature} (${u.category})`).join('\n')}

## PRODUCT KEYWORDS
${keywords.product.join(', ')}

## GENERIC KEYWORDS
${keywords.generic.join(', ')}

Generate 5-8 strategic hashtags following the categorization strategy.`

  const hashtagSchema = {
    type: 'object',
    properties: {
      hashtags: {
        type: 'array',
        items: { type: 'string' },
        minItems: 5,
        maxItems: 8,
        description: 'Ordered list of hashtags by priority',
      },
      categories: {
        type: 'object',
        properties: {
          brand: {
            type: 'array',
            items: { type: 'string' },
            description: 'Brand-related hashtags (1-2)',
          },
          features: {
            type: 'array',
            items: { type: 'string' },
            description: 'Feature-based hashtags (2-3)',
          },
          industry: {
            type: 'array',
            items: { type: 'string' },
            description: 'Industry/category hashtags (2-3)',
          },
        },
        required: ['brand', 'features', 'industry'],
      },
      reasoning: {
        type: 'string',
        description: 'Brief explanation of hashtag selection strategy',
      },
    },
    required: ['hashtags', 'categories'],
  }

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-flash-latest',
      contents: userPrompt,
      config: {
        systemInstruction,
        responseMimeType: 'application/json',
        responseJsonSchema: hashtagSchema,
        temperature: 0.4,
        maxOutputTokens: 800,
      },
    })

    const content = response.text
    if (!content) {
      console.warn('[Hashtags] No response, using fallback')
      return getFallbackHashtags(productName, keywords, language)
    }

    const parsed = JSON.parse(content)

    // Validate hashtag format
    const validatedHashtags = parsed.hashtags
      .filter((h: string) => h.startsWith('#') && h.length <= 20)
      .slice(0, 8)

    console.log(`[Hashtags] Generated ${validatedHashtags.length} strategic hashtags`)

    return {
      hashtags: validatedHashtags,
      categories: parsed.categories || { brand: [], features: [], industry: [] },
      reasoning: parsed.reasoning,
    }
  } catch (error) {
    console.error('[Hashtags] Generation error:', error)
    return getFallbackHashtags(productName, keywords, language)
  }
}

/**
 * Fallback hashtag generation when AI fails
 */
function getFallbackHashtags(
  productName: string,
  keywords: { product: string[]; generic: string[] },
  language: 'ko' | 'en'
): {
  hashtags: string[]
  categories: { brand: string[]; features: string[]; industry: string[] }
} {
  const productTag = `#${productName.replace(/\s+/g, '')}`
  const brandTags = language === 'ko'
    ? ['#Samsung', '#ÏÇºÏÑ±', '#GalaxyAI']
    : ['#Samsung', '#Galaxy', '#GalaxyAI']

  const featureTags = keywords.product
    .slice(0, 3)
    .map(k => `#${k.replace(/\s+/g, '')}`)
    .filter(h => h.length <= 20)

  const industryTags = language === 'ko'
    ? ['#ÌÖåÌÅ¨Î¶¨Î∑∞', '#Ïä§ÎßàÌä∏Ìè∞', '#Ïñ∏Î∞ïÏã±']
    : ['#TechReview', '#Smartphone', '#Unboxing']

  const allHashtags = [productTag, ...brandTags.slice(0, 1), ...featureTags, ...industryTags]
    .filter((h, i, arr) => arr.indexOf(h) === i)
    .slice(0, 8)

  return {
    hashtags: allHashtags,
    categories: {
      brand: [productTag, brandTags[0]],
      features: featureTags,
      industry: industryTags,
    },
  }
}

/**
 * Mock response for development
 */
function getMockV2Response(productName: string, keywords: string[]): GEOv2GenerateResponse {
  return {
    description: {
      preview: `${productName}Ïùò ÌòÅÏã†Ï†ÅÏù∏ Í∏∞Îä•ÏùÑ ÎßåÎÇòÎ≥¥ÏÑ∏Ïöî!`,
      full: `${productName}Ïùò Ï£ºÏöî Í∏∞Îä•Í≥º ÌäπÏßïÏùÑ ÏûêÏÑ∏Ìûà ÏïåÏïÑÎ≥¥ÏÑ∏Ïöî. ${keywords.slice(0, 3).join(', ')} Îì± Îã§ÏñëÌïú Í∏∞Îä•ÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§. Galaxy AIÏôÄ Ìï®ÍªòÌïòÎäî ÏÉàÎ°úÏö¥ Í≤ΩÌóòÏùÑ ÏãúÏûëÌïòÏÑ∏Ïöî.`,
      vanityLinks: [`samsung.com/${productName.toLowerCase().replace(/\s+/g, '-')}`],
    },
    uspResult: {
      usps: [],
      competitiveContext: '',
      extractionMethod: 'generative',
      groundingQuality: 0,
    },
    chapters: {
      timestamps: `0:00 Ïù∏Ìä∏Î°ú\n0:30 Ï£ºÏöî Í∏∞Îä•\n1:00 ÏÉÅÏÑ∏ Î¶¨Î∑∞\n2:00 Ï¥ùÌèâ`,
      autoGenerated: true,
    },
    faq: {
      faqs: [],
      queryPatternOptimization: false,
    },
    keywords: {
      product: [productName, 'Samsung', 'Galaxy'],
      generic: keywords,
      densityScore: 50,
    },
    hashtags: ['#Samsung', `#${productName.replace(/\s+/g, '')}`, '#GalaxyAI'],
    finalScore: {
      keywordDensity: 10,
      aiExposure: 15,
      questionPatterns: 10,
      sentenceStructure: 10,
      lengthCompliance: 10,
      groundingQuality: {
        citationDensity: 0,
        sourceAuthority: 0,
        coverage: 0,
        total: 0,
        breakdown: {
          citationPercentage: 0,
          tier1Sources: 0,
          tier2Sources: 0,
          tier3Sources: 0,
          sectionsWithGrounding: 0,
          totalSections: 7,
        },
      },
      total: 55,
    },
    groundingMetadata: {
      webSearchQueries: [],
      sources: [],
      citationDensity: 0,
      totalCitations: 0,
      uniqueSources: 0,
    },
    progress: [],
  }
}
